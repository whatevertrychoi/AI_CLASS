{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85493a35-fc18-41da-b80c-aa952b05ab89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minseok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 255219761152.0000 - mae: 345006.3125 - val_loss: 39861350400.0000 - val_mae: 121252.2188\n",
      "Epoch 2/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 33145329664.0000 - mae: 114242.2266 - val_loss: 36922277888.0000 - val_mae: 114505.6953\n",
      "Epoch 3/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 31121936384.0000 - mae: 109526.7188 - val_loss: 35517755392.0000 - val_mae: 112284.6250\n",
      "Epoch 4/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 30868045824.0000 - mae: 109241.5312 - val_loss: 34543063040.0000 - val_mae: 110349.9531\n",
      "Epoch 5/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 29900150784.0000 - mae: 107664.6719 - val_loss: 33981499392.0000 - val_mae: 111090.2344\n",
      "Epoch 6/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 27783233536.0000 - mae: 105018.3281 - val_loss: 34446082048.0000 - val_mae: 110132.5156\n",
      "Epoch 7/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 27753771008.0000 - mae: 104307.1484 - val_loss: 36739850240.0000 - val_mae: 118693.2656\n",
      "Epoch 8/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 28212865024.0000 - mae: 105709.3047 - val_loss: 33116213248.0000 - val_mae: 107477.8906\n",
      "Epoch 9/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 27143180288.0000 - mae: 103912.1641 - val_loss: 32868288512.0000 - val_mae: 108852.0938\n",
      "Epoch 10/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 25423910912.0000 - mae: 101005.3828 - val_loss: 34897235968.0000 - val_mae: 112756.7969\n",
      "Epoch 11/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 28024913920.0000 - mae: 102985.0312 - val_loss: 32231155712.0000 - val_mae: 105832.5859\n",
      "Epoch 12/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 26624241664.0000 - mae: 101131.9609 - val_loss: 32663982080.0000 - val_mae: 109732.8203\n",
      "Epoch 13/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 27334166528.0000 - mae: 102731.9766 - val_loss: 31202060288.0000 - val_mae: 104818.5391\n",
      "Epoch 14/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 25255020544.0000 - mae: 99674.9453 - val_loss: 30618943488.0000 - val_mae: 102171.4141\n",
      "Epoch 15/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 23700983808.0000 - mae: 96586.6328 - val_loss: 29081458688.0000 - val_mae: 99264.5391\n",
      "Epoch 16/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 23882881024.0000 - mae: 94599.2500 - val_loss: 28867131392.0000 - val_mae: 99544.1641\n",
      "Epoch 17/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 23002595328.0000 - mae: 93115.5547 - val_loss: 27573297152.0000 - val_mae: 95508.7734\n",
      "Epoch 18/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 21840660480.0000 - mae: 89851.1484 - val_loss: 26211901440.0000 - val_mae: 93079.5469\n",
      "Epoch 19/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 19916288000.0000 - mae: 87443.8906 - val_loss: 26488729600.0000 - val_mae: 92629.4375\n",
      "Epoch 20/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 21037215744.0000 - mae: 87076.4453 - val_loss: 24328443904.0000 - val_mae: 88195.3672\n",
      "Epoch 21/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 19479885824.0000 - mae: 84637.4219 - val_loss: 23853656064.0000 - val_mae: 86317.1719\n",
      "Epoch 22/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 19052083200.0000 - mae: 82669.5703 - val_loss: 24579059712.0000 - val_mae: 89578.5781\n",
      "Epoch 23/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 18658338816.0000 - mae: 81602.0938 - val_loss: 22552662016.0000 - val_mae: 84610.6562\n",
      "Epoch 24/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 16158737408.0000 - mae: 78266.5391 - val_loss: 22052958208.0000 - val_mae: 84430.4062\n",
      "Epoch 25/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 18515187712.0000 - mae: 81473.8281 - val_loss: 20967254016.0000 - val_mae: 82007.8906\n",
      "Epoch 26/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 17196611584.0000 - mae: 79356.7891 - val_loss: 22694817792.0000 - val_mae: 83726.5000\n",
      "Epoch 27/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 17270859776.0000 - mae: 78578.0625 - val_loss: 21731612672.0000 - val_mae: 84374.4922\n",
      "Epoch 28/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 15457750016.0000 - mae: 76718.7812 - val_loss: 19922608128.0000 - val_mae: 80332.6484\n",
      "Epoch 29/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 16212378624.0000 - mae: 77635.5078 - val_loss: 19932295168.0000 - val_mae: 79908.2422\n",
      "Epoch 30/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 15564455936.0000 - mae: 75655.5547 - val_loss: 20162400256.0000 - val_mae: 79992.0703\n",
      "Epoch 31/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 15425641472.0000 - mae: 76161.3672 - val_loss: 19923998720.0000 - val_mae: 80246.5234\n",
      "Epoch 32/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13512467456.0000 - mae: 72551.2031 - val_loss: 22457088000.0000 - val_mae: 85705.5547\n",
      "Epoch 33/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 15534151680.0000 - mae: 75825.6484 - val_loss: 18787338240.0000 - val_mae: 79057.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 14110662656.0000 - mae: 72957.6797 - val_loss: 19244496896.0000 - val_mae: 79674.3047\n",
      "Epoch 35/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 14221096960.0000 - mae: 73676.2578 - val_loss: 19419535360.0000 - val_mae: 81095.1094\n",
      "Epoch 36/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13853313024.0000 - mae: 72766.3281 - val_loss: 18852511744.0000 - val_mae: 78079.2109\n",
      "Epoch 37/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13940320256.0000 - mae: 73602.1719 - val_loss: 18686877696.0000 - val_mae: 77815.8281\n",
      "Epoch 38/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12863956992.0000 - mae: 71557.3984 - val_loss: 18473248768.0000 - val_mae: 78166.0312\n",
      "Epoch 39/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13377541120.0000 - mae: 71980.7969 - val_loss: 18252134400.0000 - val_mae: 77525.6719\n",
      "Epoch 40/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 13438713856.0000 - mae: 72155.6953 - val_loss: 19747612672.0000 - val_mae: 81657.5156\n",
      "Epoch 41/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13692617728.0000 - mae: 71766.6562 - val_loss: 19600640000.0000 - val_mae: 80521.1172\n",
      "Epoch 42/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 13430518784.0000 - mae: 73020.0625 - val_loss: 18708004864.0000 - val_mae: 78424.1406\n",
      "Epoch 43/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12894848000.0000 - mae: 70782.2422 - val_loss: 17543430144.0000 - val_mae: 76376.6484\n",
      "Epoch 44/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 12813566976.0000 - mae: 71046.0000 - val_loss: 18011287552.0000 - val_mae: 76052.8984\n",
      "Epoch 45/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13485824000.0000 - mae: 72237.2734 - val_loss: 18300874752.0000 - val_mae: 79868.8906\n",
      "Epoch 46/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 13960590336.0000 - mae: 72640.9688 - val_loss: 17530415104.0000 - val_mae: 76420.4922\n",
      "Epoch 47/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12058250240.0000 - mae: 69568.2266 - val_loss: 17417465856.0000 - val_mae: 75623.7891\n",
      "Epoch 48/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13038902272.0000 - mae: 71043.0469 - val_loss: 18109345792.0000 - val_mae: 77203.9219\n",
      "Epoch 49/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12288096256.0000 - mae: 70081.9141 - val_loss: 17473990656.0000 - val_mae: 74829.9531\n",
      "Epoch 50/50\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12613986304.0000 - mae: 69879.1328 - val_loss: 18164705280.0000 - val_mae: 76705.0547\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 19030054912.0000 - mae: 78547.5000\n",
      "테스트 MAE: 76705.05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "예측 가격: $695,412.25, 실제 가격: $638,000.00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "file_path = 'C:/Users/Minseok/AI_CLASS/kc_house_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 특징과 타겟 설정\n",
    "X = data.drop(columns=['price', 'id', 'date'])  # price가 타겟, id와 date는 제거\n",
    "y = data['price']\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 회귀 모델 생성 함수\n",
    "def build_regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # 회귀 문제이므로 활성화 함수 없음\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "model = build_regression_model()\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'테스트 MAE: {test_mae:.2f}')\n",
    "\n",
    "# 예측 함수\n",
    "def predict_house(index):\n",
    "    house_features = X_test[index].reshape(1, -1)\n",
    "    predicted_price = model.predict(house_features)[0, 0]\n",
    "    actual_price = y_test.iloc[index]\n",
    "    print(f'예측 가격: ${predicted_price:,.2f}, 실제 가격: ${actual_price:,.2f}')\n",
    "\n",
    "# 예제 테스트\n",
    "predict_house(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a037d-dde0-4aa9-976b-f055e55ecb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
